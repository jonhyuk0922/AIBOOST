## 오늘의 회고 : 나는 현재 밑바닥임을 항상 잊지말자.

### 오늘 배운 내용 정리
1.깃헙 특강을 통해 Vscode에서 git graph 그리는 것부터 git commit push pull(fetch + merge)에 대해 실습해보고 배울 수 있었다.
-  git commit : 내 로컬 git에 현재 버전 올리는 것
-  git push : 내 로컬 git 을 remote repo에 올리는 것
-  git pull : 원격 저장소에서 로컬 저장소로 불러오는 것 , 만약 동시에 변경하는 것이 있었다면 fetch(불러온) 후 자동으로 merge(합침) 해준다.

2. 컨볼루션 연산방식
- (padding = 0 , stride = 1) 일때 input shape 이 n 이고 filter = 3 이면 output은 n-3+1 이다. 
- stride는 한번에 몇칸씩 이동하느냐를 나타내는 파라미터고, padding은 가장자리 인식하지 못하는 것을 위해 원본 밖으로 0값을 줘서 원본 모양을 유지하는 것이다.

3. 근대 CNN 모델들의 역사
- 레이어의 깊이(Depth)가 깊어지고, 파라미터수는 줄어들며 모델이 발전해간다.
- 12년 Alexnet(8층) , 지금은 당연히 사용되지만 그 당시 대부분 최초였다. (Relu , Dropout , GPU , Augmentation 
- 14년 VGG16, VGG19 : 3 * 3 필터만 사용 e.g) 5*5 filter 하나보다 3*3 filter 2장 사용했을때 파라미터 수가 훨씬 적다.
- GoogleNet(22층) : 1 * 1 Convolution layer 를 활용하여 파라미터 값을 줄일 수 있었다.
- ResNet : Skip connection 
- DenseNet : concatenation 사용

### 피어세션 정리
1. 내가 다른 누군가보다 "먼저" 알았다고 잘하거나 안심할 것은 없다. 그저 순서일 뿐이다. 반대로 누군가 나보다 더 먼저 알았다고 기죽을 필요도 없다.
-> 현재 내게 주어진 5개월을 충실할 뿐이다. 궁금증을 가지고 답변을 얻으며 성장해가자!! (비교보단 협력!)

2. 하기 싫은 공부, 내일로 미루고 싶은 공부가 가장 큰 성장을 내게 줄 수 있다( 수학 , 코드 짜기 등)

### 질문 및 답변 정리
1. DataLoader 의 파라미터 중 num_workers 는 무슨 의미일까?
    - 원문 : num_workers (int, optional) – how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)
    - 이해한 내용 : default 0으로 설정하면 메인 프로세스에서 처리하며, 1을 값으로 주면 단일 작업자만 갖게 되어 속도가 느릴 수 있다.
    - +) 만약 worker 가 늘어나면 GPU를 잘 사용할 수 있지만, 메모리 사용량이 증가해 심각한 오버헤드가 발생할 수도 있다.

2. 모델 요약 찍어보는 방법은? 

    ```python
    #1. print문 사용 , input shape 필요없음
    model = Model()
    print(model)

    #2. torchsummary 라이브러리 사용
    import torchsummary as ts
    model = Model()

    ts.summary(model , #filter , #batch_size
    ) 

    #3.torch-model-summary 사용
    !pip install pytorch-model-summary

    import torch , torchvision
    import pytorch_model_summary

    model = Model()
    #show_input = True : input shape 출력 , False : Output shape 출력
    print(pytorch_model_summary.summary(model, torch.zeros(#input size)
    ,show_input = True)
    ```

3. 모델 만들때 혹시 순서가 Conv or linear layer + Dropout + Relu 로 안하고 Conv or linear layer + Relu + Dropout 으로 하는 이유가 있을까요???
    - 알아보다보니 BN와 Dropout이 함께 쓰일 때의 순서까지 함께 정리하면
