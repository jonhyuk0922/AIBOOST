# 일주일 회고 : 딥러닝 맛본 것에 만족한 한주였다.

## 1. 공부하며 고민한 내용 , 고민한 결과

- 답을 알지 못한 질문
    1. affine transformations 란?
    2. 과연 CE가 분류문제 loss func으로 최적일까?
    - 3. 파라미터 초기화는 왜 하며, 어떠한 방식으로 작동하여 효과가 있는 건가요?

        안녕하세요 조교 이주용입니다. 보통 딥러닝에서 파라미터들을 초기화 진행해준뒤, 학습을 진행하는 경우가 흔한데요. 이는 딥러닝의 경우 학습이 non-convex function 최적화 문제이기 때문에 성능이 별로 좋지 않은 local minimum으로 그냥 빠져버릴 수 있기 때문이 큰 것 같고, gradient update 시 vanishing problem이 일어나는 경우를 미리 막거나 하는 효과도 있습니다.

        특히 실습에서는 kaiming normalization을 썼는데, 그 외에도 역사적으로 lecun normlization, xavier normalization 등도 있는데, 각 normalization들이 효과적인 케이스들이 다 다른 것으로 이해하고 있습니다. 이 논문 (

        [https://arxiv.org/abs/1502.01852](https://arxiv.org/abs/1502.01852)

        ) 에서 he normalization(= kaiming normalization)이 소개가 되었는데, 더 관심있으시면 읽어보시는 것도 좋을듯 합니다.

        [https://blog.naver.com/PostView.nhn?blogId=handuelly&logNo=221831940317&parentCategoryNo=&categoryNo=23&viewDate=&isShowPopularPosts=false&from=postView](https://blog.naver.com/PostView.nhn?blogId=handuelly&logNo=221831940317&parentCategoryNo=&categoryNo=23&viewDate=&isShowPopularPosts=false&from=postView)

    1. Resnet 학습원리는?
    2. 
- 답을 구한 질문
    1. [relu 함수가 0일 때 미분 불가능한데 오차역전파법 적용할 때 어떻게 하는 지?](https://datascience.stackexchange.com/questions/19272/deep-neural-network-backpropogation-with-relu)

        → relu 함수에서 0보다 작은 값은 미분값0으로 , 0보다 큰 부분은 미분값 1로 나타낼수 있다. 다만 x=0인 부분에선 미분값은 0 , 0.5, 1 중 한가지 값으로 하고 있다. 세가지중 뭘하든 별 상관없고 보통은 1을 한다.

    2. DataLoader 의 파라미터 중 num_workers 는 무슨 의미일까?
        - 원문 : num_workers (int, optional) – how many subprocesses to use for data loading. 0 means that the data will be loaded in the main process. (default: 0)
        - 이해한 내용 : default 0으로 설정하면 메인 프로세스에서 처리하며, 1을 값으로 주면 단일 작업자만 갖게 되어 속도가 느릴 수 있다.
        - +) 만약 worker 가 늘어나면 GPU를 잘 사용할 수 있지만, 메모리 사용량이 증가해 심각한 오버헤드가 발생할 수도 있다.
    3. 모델 요약 찍어보는 방법은?

    ```python
    #1. print문 사용 , input shape 필요없음
    model = Model()
    print(model)

    #2. torchsummary 라이브러리 사용
    import torchsummary as ts
    model = Model()

    ts.summary(model , #filter , #batch_size
    ) 

    #3.torch-model-summary 사용
    !pip install pytorch-model-summary

    import torch , torchvision
    import pytorch_model_summary

    model = Model()
    #show_input = True : input shape 출력 , False : Output shape 출력
    print(pytorch_model_summary.summary(model, torch.zeros(#input size)
    ,show_input = True)
    ```

    1. 모델 만들때 혹시 순서가 Conv or linear layer + Dropout + Relu 로 안하고 Conv or linear layer + Relu + Dropout 으로 하는 이유가 있을까요???
        - 알아보다보니 BN와 Dropout이 함께 쓰일 때의 순서까지 함께 정리하면
        - Convolution - Batch Normalization - Activation - Dropout - Pooling 순서로 네트워크를 구성하면 됩니다.

## 2. 몇개월 후에 봤을 때 도움이 될만한 자료

- 최적화 알고리즘

    Dropout : 드랍아웃은 학습데이터에서 가까이 있는 뉴런들이 비슷한 가중치를 가지므로, 오버피팅을 피하기 위해 일정 비율 랜덤하게 뉴런을 꺼주는 것을 말합니다. 

    원리적으론 예측할 때는 모든 뉴런을 다 켜주기 때문에, 학습할 때 꺼준만큼 테스트할 때도 꺼줘야하지만 예측할 떄 연산이 끼면 느려지므로 실제 딥러닝 라이브러리들은 학습할 때, 드롭된 뉴런의 비율만큼 켜진 뉴런들의 출력을 키워준다.

    Early stopping : 모델에서 더 이상의 loss 등의 개선이 없을 경우, 학습을 중단 시키기 위해 콜백함수를 사용 합니다.

    ```python
    tf.keras.callbacks.EarlyStopping(
     monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto',
     baseline=None, restore_best_weights=False )
    ```

    - 파라미터 설명
        - monitor : 멈추는 기준값
        - min_delta : 개선되고 있다고 간주할 최소한의 변화량
        - patience : 개선되지 않고 있을 때 최선의 값 기준 몇번더 학습할지
        - baseline : 모델이 달성해야할 최소한 기준값 , 만약 patience 안에서 baseline 아래로 내려가면 종료한다.
        - verbose : 학습과정 시각화 여부(1이 긍정)
        - restore_best_weights : True일 경우 학습종료 후 가장 좋았던 가중치로 복원, False일 경우 학습종료 시점 가중치
        - mode : "auto" , "max", "min" : 모니터하는 값이 큰게 좋은 지 작은게 좋은 지 , 알아서 판단하라고 할 지 결정

    Parameter norm penalty : 부드러운 함수일수록 일반화 잘될 것이라는 전제하에 웨이트를 함께 줄어주는 것. weight decay라고도 부른다. 

    Data augmentation : 데이터가 많을 수록 과대적합 피할 수 있다. (왜냐면 다양한 경우를 만날 수 있으니까.. e.g) 서있는 강아지 돌려서 누워있는 강아지 학습에 도움주는 데이터 증강 가능해짐)

    Noise Robustness : 입력데이터와 웨이트에 노이즈를 넣어준다. 이렇게 하면 성능이 더 잘 나온다. (왜 잘되는 지 모름)

    Label smoothing : 데이터 두개를 뽑아서 섞어준다. 이를 통해 이미지 분류같은 경우 결정기준을 부드럽게 만들어준다.  (Mix up , CutMix) 가성비가 좋다 ㅎ..

    k-fold validation : 

    Weight decay : 

    [Batch normalization :](https://eehoeskrap.tistory.com/430) 

    Mixup :

    Ensemble : 

    Bayesian Optimization : 

- 엔트로피와 크로스 엔트로피의 차이는?

    (정보량 and 엔트로피) [https://angeloyeo.github.io/2020/10/26/information_entropy.html](https://angeloyeo.github.io/2020/10/26/information_entropy.html)
    (크로스 엔트로피 and KL-Divergence) [https://angeloyeo.github.io/2020/10/27/KL_divergence.html](https://angeloyeo.github.io/2020/10/27/KL_divergence.html)

    KL-Divergence (두 확률분포의 차이) = P(x)의 정보 엔트로피 - P(x) 기준 Q(x) 의 크로스 엔트로피 (손실함수)
    => 크로스 엔트로피 최소화의 의미 = P(x) 와 Q(x)가 비슷해지는 정도
    => 당연히 P(x) = Q(x) 일 때, KL-Divergence 값이 0이 되므로 가장 좋은 성능이겠지만 사실상 거의 불가능

- 최적화에서 주요한 용어들(Important Concepts in Optimization)
    1. Generalization(일반화)
        1. 모델이 학습하지 않은 데이터에 대해도 잘 동작할 수 있도록 하는 것
        2. Underfitting(과소적합) vs. Overfitting(과대적합) 이 두 가지 중간 어딘가 balanced에 도달하는 것이 목표다. 과소적합은 학습 데이터조차 잘 못맞추는 경우, 과대적합은 너무 학습데이터에 맞춰진 경우
    2. 교차검증(Cross-validation)
        1. 방법 중 하나가 k-fold validation , 즉 k개로 전체 학습데이터를 나눠서 학습할 때마다 test set을 바꿔줌으로 과대적합 되는 걸 방지한다. (여기서 test set은 validation set을 의미함) 

            교차 검증을 하며 최적의 hyper parameter(우리가 정해주는 파라미터 값 eg. lr , batch size , epochs etc) 를 정할 수 있다.

            ![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/37722904-6eb3-4f9d-988b-2c28284c5f8e/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/37722904-6eb3-4f9d-988b-2c28284c5f8e/Untitled.png)

    3. 편향과 분산(Bias and Variance)
        1. Variance : Input에 대해 Output들이 일관되게 나오는 지 여부. 높을 수록 퍼져있는 구조이며 과대적합될 가능성이 커진다.
        2. Bias : 원하는 타겟값과 가까운 지 여부. Output값들의 평균이 타겟값과 가깝다면 Low Bias , 타겟값과 멀다면 High Bias이다.

            ![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ed40ba7a-e26f-4ea6-9e4c-f606835901fb/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ed40ba7a-e26f-4ea6-9e4c-f606835901fb/Untitled.png)

        1. Bias and Variance Tradeoff : 내 학습 데이터에 노이즈가 껴있다고 가정했을 때, 계산 비용(Cost)을 줄여주기 위해선 bias, variance , nosie 이 3가지를 줄여주는 것으로 볼 수 있다. 

            그러나 근본적으론 bias 와 variance는 서로 상반되어서,이를  Bias and Variance Tradeoff라고 부릅니다. (train set에 학습잘되면 (b) 처럼 test set에 variance 가 높아진다.  train set에 학습이 덜된다면 (c)와 같이 bias가 높아진다.

    4. Bootstrapping
        1. Bootstrapping is any test or metric that uses random sampling with replacement.
        2. 학습데이터가 고정되어있을 때, 샘플링을 통해 여러개를 만들고, 여러 모델을 만들어 하겠다.
    5. Bagging vs. Boosting
        1. 앙상블이 배깅에 속한다. 앙상블은 맨 마지막에 나온 출력값들의 평균을 내주는 것.
        2. 부스팅 : 앞에서 잘 안된 것에 대해서만 모델을 만든다. weak learner들을 합쳐서 하나의 strong learner로 만든다.
- Inductive bias

- 병목현상이란?

- 깃헙 강의들었던 것 정리할 겸 똑같이 따라해보고 영상남기기

## 3. 더 공부해보고 싶은 내용

1. SimCLR : a simple framework for contrastive learning of visual representations

→ self-supervised learning이 궁금하다 궁금해!

1. 옵티마이저 : Adam 이후에 어떤 것들이 나왔나? [Radam](https://github.com/LiyuanLucasLiu/RAdam) , [adamP](https://github.com/clovaai/AdamP)
2. Attention is all you need 3회독 및 코드 구현 3회!!!

## 4. 한주 회고

- 기억에 남기고 싶은 메세지들
    1. 주니어는 MLOps 도 물론 중요하지만 자료구조, 알고리즘 등 기초 CS 갖추는 것도 중요하다. 어려운 것들은 필요하다면 그때 자연스레 공부하게 될 것이다.
    2. 배운 것중에 관심있는 분야에 대해 무언가 만들어보자!! (MNIST 라도 좋으니 배운 걸 적용해보기 , 농구 데이터로 시각화해보기 등)
    3. 이고잉님이 새로운 페이지가 나올떄마다 하셨던 말씀 , "관찰하세요" 내가 공부할 때 어려워하는 이유는 조급해서 관찰없이 돌입해버려서 일 수도 있겠다 싶었다.
- 피드백(잘3, 못3)

    +1) 피어세션간 발언권이 골고루 돌아가도록 의식하며 캠퍼들에게 말을 걸었다.

    +2) 지난주에는 굿노트에 필기만하고 정리를 못했는데, 이번주는 배운 개념들을 노션에 잘 정리했다. 몰랐던 부분들도 잘 기록해둔 덕분에 복습할 때마다 채워나갈 수 있다.

    +3) 질문을 많이 던진 만큼 더 공부해볼 수 있었다. 커리큘럼 외에 추가공부를 해볼 수 있었다.

    -1) 계속 몸에 안좋은 것들만 먹고, 잠을 늦게자면서 컨디션 조절을 잘 못해서 아침, 밤으로 허비된 시간이 많다.

    -2) 선택과제를 깊이있게 고민해보지 못했다. 최대한 러닝타임 내에 개념적인 부분들을 정리해야 저녁먹고 심도있게 고민해볼 수 있다. 

    -3) 팀원들에게 설명할 때 짐작하듯이 설명하거나 말로만 설명했다. 한장의 이미지라도 꼭 곁들이고 , 여유있게 설명하는 연습을 해야겠다.

> 적용점

1. **피어세션 전에 최소1시간은 강의말고 질문 만들고 답해보기!! (설명자료도 만들기)**
2. **일주일간 무언가 "만들어보기" e.g) 케글 , 빵형 , 시각화 뭐든 좋다.**
3. **코어타임 이후에 선택과제 해보기**
