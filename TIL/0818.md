# 구현할 줄 알아야 아는 것이다. 구현할 줄 알아서 자는 거지?

## 1. 오늘 새로 알게된 내용

---

1.1 torch.nn.Module 

- Layer의 base class로, Input , Output , Forward , Backward) 를 정의해줘야한다.
- 학습대상이 되는 parameter(tensor)정의한다.

1.2 torch.nn.Parameter

- nn.Module 내에 attribute가 될때는 required_grad=True(Autograd)로 지정하여 학습대상이 되는 Tensor
- 대부분 layer에는 weights 값들이 지정되어있어, 직접 지정해줄 일은 잘 없다.

1.3 Data feeding flow

1. (collecting & cleaning & preprocessing)Data
2. Dataset (init , len , getitem) : 초기 데이터 입력 형태 정의 , 데이터 전체 길이 정의, index값마다 반환되는 데이터 형태(map-style) 정의
3. DataLoader (batch , shuffle ...) : 배치를 나눠서 먹일수 있도록 해준다. 학습 직전 데이터의 변환을 책임진다.

## 2. 공부하며 고민한 내용 & 고민한 결과

---

질문1. HuggingFace가 뭐지?? 

→ pretrained & fine tunning model 이 있는 사이트이름! (표준임)

질문2. Dataset 클래스 생성할 때, 데이터 형태에 따라 각 함수를 다르게 정의한다는 게 무슨 뜻일까?

> 피어세션 정리

- 1.논문리뷰_진영님(BERT)

    BERT를 직역하면 트랜스포머 기반 양방향 인코더 표현이다.

    레이블링되지 않은 문장들을 사전학습한 모델 사용.

    - 등장 배경

        파인튜닝 영역의 대표격인 단방향 모델들의 한계 존재 → 모든 토큰이 바로 직전(left) 토큰들에 한해서 self-attention

    - 비슷한 모델들 비교
        - ELMo : 얕은 양방향 , 왜냐면 학습할때 LSTm이 단방향이기 때문이다.
        - GPT : 단방향 모델 , 앞에 있는 문맥을 통해 뒤에 올 단어 예측
        - BERT : 마스킹한 부분을 추론. → 질문 : 마스킹은 테스트 셋에서 하는건가? 트레인셋에서 한다.
    - 모델 구조(Architecture)

        마스킹은 인풋들어갈 때 랜덤하게 적용되고, 아웃풋으로 예측값이 나온다. (인코더?)

        → 80프로 마스킹, 10프로 랜덤, 10프로는 원래값을 넣어준다. (일반화를 위해서?)

        base vs large : 인코더 부분인가 디코더 부분인가? (아마 인코더)

        Q. 단방향 모델보다 양방향 모델에서의 단점은? 각 사용처가 어떻게 다른가?

    - 사전학습

        문장단위로하면 문맥 끊겨서 문서단위로 학습시켰다. (약 33억개)

    - Hugging Face

        이미 사전학습된 여러 모델들 구할 수 있다. 파인튜닝 모듈도 구할 수 있다.

## 3. 몇개월 후에 봤을 때 도움될 자료

---

1. torchvision datasets source code 클론 코딩해보기  : [https://pytorch.org/vision/stable/datasets.html](https://pytorch.org/vision/stable/datasets.html)

    → dataset이 너무 많은데 뭘 해보면 좋을까?

2. DataLoader parameter 설명 : [https://subinium.github.io/pytorch-dataloader/](https://subinium.github.io/pytorch-dataloader/)
3. [논문리뷰] DNN for Youtube recommendations : [https://jonhyuk0922.notion.site/Deep-Neural-Networks-for-YouTube-Recommendations-3f70420b77254c57a86449bc20fe6095](https://www.notion.so/Deep-Neural-Networks-for-YouTube-Recommendations-3f70420b77254c57a86449bc20fe6095)

## 4. 회고

---

모델을 구현할 수 없는데 안다고 할 수 있을까? AI개발자라고 부를 수 있을까? 이 고민 속에 자신감을 얻고자 부캠에 지원했다. 그런데 막상 파이토치 코드앞에 서면 도망치고 싶어한다. 

이번에 과제들이 길지만 친절하고 파이토치 실력을 늘리기엔 너무나도 즣은 기회다. 논문 구현을 위한 기초근육을 기를 수 있어 내가 지원한 이유에 부합한 한주가 되어야한다. 그런데 왜 자꾸 과제가 하기 싫지?..

이유를 생각해봤을 때, 부딪히는 것에 대한 두려움 그리고 그로 인한 시간 소모에 대한 두려움이 있는 것 같다. 

⇒ 내일은 오전시간에 첫번째 필수과제를 8시 ~ 11시 최대한 해보고 하루를 시작하자! 과제양에 쫄지말고 일단해보자. 그러고 오후에 강의들어도 늦지 않는다.
