# 오늘의 회고 : 오래 공부하려면 운동이 필수적인 것 같다.

# 1. 수업 & 피어세션

---

- 피어세션 정리
    - 1.진용님 논문 리뷰_YOLO

        You Only Look Once  → 한번만 봐도 O.K.

        - 활용분야 : 마스크 착용 여부 분별 (빵형)
        - 모델 소개

            사람은 이미지를 볼때 한번에 여러 객체를 파악하지만, 기계는 그게 안됐었다. 그러나 YOLO는 그것이 가능해진다. → 의식하지 않고 인식이 가능해지면 , 운전이 가능해진다.

            한번 본 것을 기억한다?

        - 모델 알아가기

            Confidence score : class가 존재하면 IOU , 아니면 0 

        - 모델 구조

            구글넷을 본따옴. 어렵다..

            class score 0.2보다 작으면 0으로 수렴 후 sort.

            NMS 알고리즘 : 가장 점수가 높았던 바운딩 박스의 겹치는 부분을 IOU라고 한다. 만약 겹치는 부분의 IoU가 0.5보다 크면 두번째 박스는 0으로 바꾼다. 

            Q. FPS , mAP 는 어떤 수치인가? 

            Q. 정답을 박스 쳐놓고 시작하는 것인가? 네! (지도학습임) 

            어떤 기준으로 박스 치는가? → precision과 recall 둘다 중요한데, 꿀벌같은 경우는 날개까지 다 하려다보면 배경이 많이 들어온다. 이런 경우 precision이 더 중요하다.

    - 2.필수과제1 코드리뷰
        1. gather 사용법 

            → 0,1,2 넣을 때마다 다르다.

        2. init 함수에서 super().__init__()해주는 이유는?

            →  토치의 모듈 클래스(부모)에서 상속받는 것이므로 super로 부모의 init에 속한 특성들을 가져와야한다.

        3. module에서 하위모듈 불러올때(get_submodule) self가 뭐지?? 

            → self에 Model() 넣어주고 뒤에 target에 경로(ab.a) 넣어주니까 풀림

        4. model에서 parameter , buffer 갯수 찾는 방법은?

            → len로 해결

        5. repr 의 개념 ? 

            → repr(Function_A) ⇒ Function_A.__repr 이 반환된다.

            정보를 추가하고 싶을 때 extra_repr쓰면 기존 repr대신 작동한다.

            partial이 변수에 함수를 할당할 수 있다.

        6. 흑마법
            1. data.fill_(1.) : 전부다 1로 채운다.
            2. 여기서도 partial이 중요
    - 3.이번주 수업 질문 내용 확인
        1. gather 사용법 (해결)
        2. BERT를 실제로 서빙할 때 용량이 큰 pre-trained 모델이 문제가 되지 않는가 (멘토링 질문)
    - 4. 공지사항
        1. 금요일 논문은 다음주로 넘긴다.
        2. 과제2 는 대략 2~4시간 걸린다. (금요일 오전 11시 55분까지 해야함)
- 필수과제1 질문
    1. gather 사용법
    2. init 함수에서 super().__init__()해주는 이유는?
    3. module에서 하위모듈 불러올때(get_submodule) self가 뭐지?? 
        1. self에 Model() 넣어주고 뒤에 target에 경로(ab.a) 넣어주니까 풀림
    4. model에서 parameter , buffer 갯수 찾는 방법은?
- 강의내용

    구글 드라이브 마운트, torch summary 권장

    userwarning 지우는 코드 추천

    checkpoint code 중요! 

    vgg 마지막에 fc layer로 output 1로 만들어준다.

    전이학습할 때 프로즌 코드 꼭 추가해줘야한다.

    저장한 모델 슬렉으로 보내는 코드?

---

# 2. 마스터 클래스

---

> 교수님 스토리

1. 입사했으나 부서없어지며 보고위주 업무를 하다가 회사 나옴
2. 회장님께 보고하다보니 스토리 정리를 잘하게 됐다. 그러다보니 파이썬 강의가 인기가 많았다.
3. 어쩌다보니 해양 AI를 하고 있다. 요즘엔 게임엔진을 가지고 조선소 그려본다.

⇒ 모든 경험은 의미 , 아직 많이 남음

> Data centric AI

- 결론 : ML/DL은 코딩을 잘해야한다!
- 현재 추세 : 전이학습이 가능하므로 컴퓨터를 잘 쓰는 것이 중요하다. 성능을 올리기 위한 모델싸움은 예전보단 덜 치열해졌다. (오히려 모델의 크기를 줄이는 것이 더 중요)
- 이제는 데이터다!!!
- Research ML : 모델 개발/ 하이퍼파라미터 튜닝 싸움

![스크린샷 2021-08-19 오후 6.16.50.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d1afd283-7916-4bc6-8961-940715a6c09e/스크린샷_2021-08-19_오후_6.16.50.png)

- Project-Real World ML : 실제론 문제 정의 ->성능 기준점 → 모델링 → 서빙
- 사실... 산업분야에서 ML code는 매우 작은 부분

![스크린샷 2021-08-19 오후 6.19.38.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6871d882-9f29-4d28-897f-396da5a47e9b/스크린샷_2021-08-19_오후_6.19.38.png)

> 우리의 미래는 DATA ?!

1. Data : 실제 프로젝트에선 데이터 확보가 관건이다.
- Data Flywheel (데이터 선순환) : 사용자들의 참여로 데이터를 개선하는 것이 중요하다.
- 데이터는 계속해서 바뀐다. 추천방법 : 2-4주 지나서 새로운 데이터로 학습시켜본다. 이때마다 다이나믹 하이퍼파라미터 튜닝해줘야함.
- 테슬라와 다른 회사(웨이모)의 차이
    1. 테슬라는 라이다 , 레이다 아예 안쓰겠다 선언함!(CNN만 쓰겠다!)
    2. 다른 회사들은 시뮬을 통해 얻는 반면, 테슬라는 데이터를 실 유저들의 이용을 통해 만든다(사람들의 사망 포함..) → 데이터를 모으고 핸들링하는 역량이 압도적이기 때문에 아마 다른 회사들이 이기기 힘들 것이다.
- Data Feedback Loop : 사용자 데이터를 자동으로 모델에 피딩하는 체계

    → 대용량 데이터를 다뤄본 경험이 중요!!

1. 앞으로 알아야할 것들
    - MLOPs 도구들 + DB(SQL) + Cloud (AWS , GCP , AZure)
    - Spark(+~~Hadoop~~) + Linux + Docker + 쿠버네티스
    - 스케줄링 도구들(쿠브플로우 , MLFlow , AirFlow)

    ⇒  신입이 갖추기 힘든 역량이지만 요한다.. 그러나 그 도구들과 하나하나 가까워 져야한다.

2. 하나의 시스템으로서 ML/DL **기획**
    1. 전통 제조업에 가보면 데이터는 ... "없다" 
    2. 개발도 잘해야하지만, 데이터를 어떻게 체계적으로 수립(Feedback loop)할 것인 지 기획하는 능력도 필요하다.
    3. 제조업 회사에선 데이터에 대한 이해가 부족하다. (예를 들어, 데이터가 있다고 해서 가보면 디지털화가 안되어있다.) 이런 곳에 디지털 전환의 역량을 갖춘 인재가 필요하다. 

        a.p] MLOps 역량도 중요하지만 기획의 역량도 필요하다!

## 결론

1. 앞으로는 알고리즘 연구자보다 ML/DL 엔지니어의 필요성이 더 증대
2. 단순히 ML/DL 코드 작성을 넘어서야 함

    → 자동화하고, 데이터와 연계, 실험 결과를 기반으로 설득,시스템화

3. 좋은 엔지니어이자 좋은 기획자적인 요소들이 필요

    → 아직 AI화 되지 않는 영역의 AI화(데이터를 어떻게 먹일 것인가!)

4. Shell script, 네트워크, 클라우드 등 기본적으로 알아야 할 것들이 많음.. (너무 많음)

## QnA

1. 클론 코딩하면 좋을만한 자료는 ? 

    → 구글에서 만든 코드, 프로젝트 템플릿 코드 보는 것 추천 (옛날것말고)

2. CS지식 부족한 통계학과 출신인데 뭐부터 공부해야할까요?

    → 1)Linux에 익숙해지고 , 2)DB를 다룰줄 모르면 협업을 하기가 힘들 거다. 그다음은 3)클라우드, 그 위에서 작업하기 때문이다.

    → 4) Docker , 대용량 데이터를 다루기 위해선 멀티노드 프로세싱해야함. 5)Spark 코드 정도는 읽고 이해할 수 있는 능력!

3. 최종 Goal로 잡을 만한 것들이 무엇이 있을까요?

    → 행복하게 살고싶습니다. 살다보니 데이터 다루는 게 즐거워서 즐거울때까지 하고 싶다.

    → AI 시스템 기획부터 개발까지 하는 리더가 되고싶다!

4. 학사출신으로서  갖출만한 경쟁력은?

    → 연구경험 = 문제를 정의하고 해결했던 경험이다. 케글같은 컴피티션 참여해보고 결과를 정리해서 포스팅해보는 것이 연구를 대체할 수 있을 것 같다.

    → 우리가 생각하는 좋은 회사에 간다면, 논문을 내는 것이 당연하다. 대학원에서 배우는 게 좋지만 그게 아니라면 문서를 정리하고 글을 써보는 연습을 하는 것을 추천한다.

---

# 3.멘토링

---

# QnA with 멘토님

- 1. 현업에서 엔지니어와 리서처의 업무 분리궁금합니다. 그리고 대학원에서 모델을 만든다고 하시면 어디서부터 어디까지 하시나요?
    - 엔지니어와 리서처의 업무 분리가 불분명한 부분이 꽤나 있다. 둘다 모델을 구현해야하는 영역에서는 겹친다.

        구분된다기보다 "비율"의 문제로 보는 게 좋다.

    - 엔지니어 : API 개발 , 개발 환경 및 인프라 구축, 모델 개발부터 테스트까지 각 과정 캡슐화(모듈화) , 서빙할 때 속도 최적화가 안되면 만족도가 떨어진다. 개발 문서에 익숙, 최신 프레임워크 지속적 팔로업
    - 리서처 : ML 모델 혹은 서비스에서 문제를 찾고, 해결방안을 제시해야한다.

        문제를 찾고, 해결방안 모색하는 과정은 석박사를 진행하는 과정과 유사하다. 주로 관련 논문들에서 내가 생각하는 문제와 비슷한 걸 해결했었다면 그걸 적용하고, 만약 없다면 새로운 방법 제시할 수 있어야한다.

    > 정리 : 리서처가 문제 찾아서 해결하는 프로토타입 만들면, 그걸 최적화하고 서빙하는 것은 엔지니어!

    크게보면 리서치는 두가지다.  SOTA보다 잘하겠다 vs 기존에 없던 테스크를 찾아서 풀어보겠다.

    → 케글은 후자에 해당되지 않고, 케글 잘하는 분들의 전략을 보면 기존의 기술들로 짜내서 끌어올리는 것이다보니 새로운 솔루션을 찾는 것과는 다르다. (즉 , 한계가 있다.)

- 2. Bert 같이 용량 큰 pre-trained 모델이 문제가 되지 않을까요?

    문제가 됩니다. (예를들어 챗봇) 인퍼런스 타임이나 최적화가 사용자의 만족도에 직결되는 부분이 많기 때문에, 

    ML 경량화가 필요하다. 이 부분은 모호하지만 주로 엔지니어의 영역이다.

- 3.실제로 쓰시는 성능 높이시는 Tip 알려주세요.
    - 하이퍼 파라미터 튜닝 : 시각화된 결과를 통해서 조절한다. 진동할 때 → lr 조절, 과대적합되면 dropout rate 증가 (보통 이미지에선 다 넣는다)
    - 기법 : lr(1e-3에서 시작) 는 주요 실험이 끝난 후 나중에 작게 조절 , 메모리가 꽉찰 때까지 배치사이즈 늘려보기.
    - 학습하는데 시간이 별로 안든다면 처음엔 early stopping 없이 해본다. 옵티마이저는 주로 아담쓸 것이다.
- 4.CV vs NLP

    CV는 결과가 확실하게 보인다. 논문 쓰기도 편하다. 이미 기술적 수준이 적용가능한 수준에 도달한 분야가 많다.(공정 불량품 판단, 자율주행 ,의료 등)

    또한, 연구도 엄청 많이해서 세계적으로 탑티어가 CVPR이다. (제출 수, 참여자수가 압도적) 단점은 그렇다보니 연구쪽에선 레드오션이다. 

    NLP는 결과를 내기가 모호해서 파고파고 계속들어가야한다. 아직 기술 수준이 현실에서 쓰이는 경우가 많이 없다. 가장 대표적인게 '번역' 외엔 없다. 기껏해야 가장 화두가 되는 게 '챗봇'인데 개선되어야할 부분이 많다.

    챗봇의 경우 답변을 잘못했을때 수정할 방안이 없기에 정교해야하고, 전체의 파이프라인이므로 손볼 곳도 많다.

    그럼에도 GPT-3같은 모델이 나왔는데 산업 측면에선 호재다. NLP도 CV처럼 현실에 적용할 수 있는 것이 나왔다. 다만 연구자 입장에선 large scale이 downstream task에서 잘된다는 걸 입증하면, 영세자들은 입지가 작아진다. ⇒ 자리가 없어졌다기보다 해야할 분야를 명확히 해줬다. 

    e.g) (영세자는) 내가 하려는 것을 task 간소화해서 해본다? , 언어모델 연구자 줄었다. 만약 큰 task, 언어모델 연구가 하고싶다면 "네이버를 가라!"

- 5.대학원 가야하나요?

    2년간 고민하면서 성장할 수 있음. 좋은 랩들어가면 선배논문 협업 하다보면 논문도 써볼 수 있다.

    석박은 자신과의 싸움이기때문에, 최소한 나 자신만큼은 확실히 설득하고 가야한다!! (조금이라도 의심이 든다면 노노! 가지마라)

    - 그러면 어떻게 가나요? ... 인턴해보면 갈 수 있나요? 학점 컷인가요??
